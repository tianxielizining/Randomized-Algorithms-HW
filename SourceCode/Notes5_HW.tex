\section{Hoeffding's Inequality}
\noindent 0. \blue{Assume that there is a randomized algorithm $A$ that is suitable for a yes/no problem.
And algorithm $A$ can return the correct answer with probability $p\in(\frac{1}{2},1)$. 
How to design a randomized algorithm based on $A$ with failure probability at most $\delta$? } \\
\textbf{Algorithm:}\\
\begin{enumerate}
    \item  Repeat algorithm $A$ for $2n+1$ times and we can get $2n+1$ outputs.
    Denote the $2n+1$ outputs as $X_0,X_1,...,X_{2n}$. Here, $n=\lceil \frac{-8p\cdot \ln \delta }{2(2p-1)^2} -\frac{1}{2}\rceil $.
    \item Let $X$ be the output of the algorithm. 
    If $\frac{\sum_{i=0}^{2n}X_i}{2n+1}\ge \frac{1}{2}$, return $X=1$. Otherwise, return $X=0$.
\end{enumerate}
\textbf{Analysis:}\\
Let $C$ be the correct answer, and $C\in\{0,1\}$.
For each $i\in [2n+1]$, $X_i\in \{0, 1\}$. 
For each $i\in [2n+1]$, use $Y_i$ to denote the correctness of $X_i$.
If $X_i=C$, $Y_i=1$; if $X_i\neq C$, $Y_i=0$. 
Since the algorithm $A$ can return the correct answer with probability $p$, 
we have for each $i \in [2n+1]$, $E[Y_i]=p$.
Let $Z=\sum_{i=0}^{2n}Y_i$, and then, we have $E[Z]=(2n+1)p$.\\
The algorithm will fail if and only if $Z$ is lesser than $\frac{1}{2}(2n+1)$. 
And we have to make sure that the failure probability at most $\delta$, so we have:
\begin{align}
    \nonumber  \Pr[Z\le\frac{1}{2}(2n+1)]\le \delta
\end{align}
By Chernoff bound, we have:
\begin{align}
    \nonumber \Pr[Z \le (1-\epsilon) E[Z]]\le \exp({-\frac{1}{2}\epsilon^2(2n+1)p})
\end{align}
Let $(1-\epsilon) E[Z]= \frac{1}{2}(2n+1)$. Since $E[Z]=(2n+1)p$, we can compute $\epsilon=1-\frac{1}{2p}$.
Since $p\in (\frac{1}{2},1)$, the $\epsilon \in (0,1) $.
Thus, we have $\Pr[Z \le \frac{1}{2}(2n+1)]\le \exp({\frac{-(2p-1)^2(2n+1)}{8p}})$.
Since we have to satisfy $\Pr[Z\le\frac{1}{2}(2n+1)]\le \delta$, then:
\begin{align}
    \nonumber \exp({\frac{-(2p-1)^2(2n+1)}{8p}}) \le \delta \implies 2n+1 \ge \frac{-8p\cdot \ln \delta }{(2p-1)^2}
\end{align}
\\
\noindent 1. \blue{\textbf{Integration by Sampling.}
Suppose we are given an integrable function 
$f : [0, 1]\rightarrow [0, M ]$,
and we wish to estimate the integral $I (f ) := \int_{0}^{1} f (x) \,dx$.
We only have \textbf{black box access} to the function $f$: 
this means that we are given a box such that 
when we provide it with a real number $x$, 
the box returns the value $f(x)$.
Moreover, we assume the real computation model. 
In particular, we assume that storing a real number takes constant space, 
and basic arithmetic and comparison operator ($\le$) take constant time.
Suppose we are also given a random number generator \textbf{Rand[0,1] }
that returns a number uniformly at random from $[0,1]$, 
and subsequent runs of \textbf{Rand[0,1]} are independent.
The goal is to design an algorithm that given black box access to a function 
$f : [0, 1]\rightarrow [0, M ]$ and parameters $0 < \epsilon ,\delta < 1$, 
return an estimate of $I(f)$ with additive error at most $\epsilon$ 
and failure probability at most $\delta$.
\\
(a) Show that this is not achievable by a deterministic algorithm. 
In particular, show that for any deterministic algorithm $A$, 
there is some function $f$ such that the algorithm $A$
returns an answer with additive error $\frac{M}{2}$ .
}\\
If algorithm $A$ does not rely on the black box, 
that is to say, 
no matter what the function $f(x)$ is, it always return a constant $c$.
If $C\le\frac{M}{2}$, we can set $f(x)=M$. If $C>\frac{M}{2}$, set $f(x)=0$.
Thus the additive error is at least $\frac{M}{2}$.\\
If algorithm $A$ accesses to black box for finite times, say $n$.
And get $(x_1,y_1),(x_2,y_2),...,(x_n,y_n)$ from black box.
Since algorithm $A$ is an deterministic algorithm, once $(x_1,y_1),(x_2,y_2),...,(x_n,y_n)$ are fixed, 
algorithm $A$ can only return the same answer. 
However, the only requirement for $f(x)$ is to pass through the points $(x_1,y_1),(x_2,y_2),...,(x_n,y_n)$,
so we can construct infinite functions, and the integral of the functions in $[0,1]$ is from $0$ to $M$.
Same as the previous case, we can always find a $f(x)$ so that the additive error is at least $\frac{M}{2}$.
\\
Since algorithm $A$ is a deterministic algorithm, $A$ is not allowed to access to the black box for infinite times.\\
\noindent \blue{(b) Using the random generator \textbf{Rand[0,1]}, 
design a randomized algorithm to achieve the desired goal.
Give the number of black box accesses to the function $f$ 
and the number of accesses to \textbf{Rand[0,1]} used by your algorithm.}\\
The randomized algorithm is as follows.
\begin{enumerate}
    \item Use \textbf{Rand[0.1]} for $n$ times and get $n$ random numbers.
    Here, $n=\lceil \frac{M^2(\ln \frac{2}{\delta})}{2\epsilon^2}\rceil $.
    Denote the $n$ random numbers as $X_0, X_1, ..., X_{n-1}$.
    \item For each $X_i$, $i\in [n]$, use \textbf{black box access} to get $f(X_i)$.
    Let $Y=\sum_{i\in n}f(X_i)$.
    \item Return $\frac{Y}{n}$ as the estimate of $I(f)$.
\end{enumerate}
\textbf{Analysis:}\\
Since \textbf{Rand[0,1]} can generate random number independent,
$X_1, X_2,..., X_{n-1}$ are independent.
And then, $f(X_1), f(X_2),..., f(X_{n-1})$ are independent.
Furthermore, all of the $f(X_i)$s take values from the interval $[0, M]$.
$Y=\sum_{i\in n}f(X_i)$, by definition, we have $E[\frac{Y}{n}]=I(f)$.
By Hoeffding's Inequality, we have:
\begin{align}
    \nonumber \Pr[|\frac{Y}{n}-I(f)|\ge\epsilon]=\Pr[|\frac{Y}{n}-E[\frac{Y}{n}]|\ge\epsilon]
    =\Pr[|Y-E[Y]|\ge n\epsilon]\le 2\exp({\frac{-2n\epsilon^2}{M^2}})
\end{align}
What we need to satisfy is $\Pr[|\frac{Y}{n}-I(f)|\ge\epsilon]\le \delta$, then,
\begin{align}
    \nonumber 2\exp({\frac{-2n\epsilon^2}{M^2}}) \le \delta \implies n\ge \frac{M^2(\ln \frac{2}{\delta})}{2\epsilon^2}
\end{align}
3.\blue{\textbf{Estimating the (Unknown) Fraction of Red Balls.}
Suppose a bag contains an unknown number of red balls (assume there is at least one red ball) 
and you are only allowed to sample (with replacement) uniformly at random from the bag. 
Design an algorithm that, given $0<\epsilon,\delta <1$, with failure probability at most $\delta$, 
returns an estimate of the fraction of red balls with multiplicative error at most $\epsilon$,
i.e., if the real fraction is $p$, the algorithm returns a number $\widehat{p}$ such that $|p-\widehat{p}|\le \epsilon p$.
Give the number of random samples used by your algorithm.
}
