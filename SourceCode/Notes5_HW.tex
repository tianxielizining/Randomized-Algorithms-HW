\section{Hoeffding's Inequality}
\noindent 0. \blue{Assume that there is a randomized algorithm $A$ that is suitable for a yes/no problem.
And algorithm $A$ can return the correct answer with probability $p\in(\frac{1}{2},1)$. 
How to design a randomized algorithm based on $A$ with failure probability at most $\delta$? } \\
\textbf{Algorithm:}\\
\begin{enumerate}
    \item  Repeat algorithm $A$ for $2n+1$ times and we can get $2n+1$ outputs.
    Denote the $2n+1$ outputs as $X_0,X_1,...,X_{2n}$. Here, $n=\lceil \frac{-8p\cdot \ln \delta }{2(2p-1)^2} -\frac{1}{2}\rceil $.
    \item Let $X$ be the output of the algorithm. 
    If $\frac{\sum_{i=0}^{2n}X_i}{2n+1}\ge \frac{1}{2}$, return $X=1$. Otherwise, return $X=0$.
\end{enumerate}
\textbf{Analysis:}\\
Let $C$ be the correct answer, and $C\in\{0,1\}$.
For each $i\in [2n+1]$, $X_i\in \{0, 1\}$. 
For each $i\in [2n+1]$, use $Y_i$ to denote the correctness of $X_i$.
If $X_i=C$, $Y_i=1$; if $X_i\neq C$, $Y_i=0$. 
Since the algorithm $A$ can return the correct answer with probability $p$, 
we have for each $i \in [2n+1]$, $\mathbb{E}[Y_i]=p$.
Let $Z=\sum_{i=0}^{2n}Y_i$, and then, we have $\mathbb{E}[Z]=(2n+1)p$.\\
The algorithm will fail if and only if $Z$ is lesser than $\frac{1}{2}(2n+1)$. 
And we have to make sure that the failure probability at most $\delta$, so we have:
\begin{align}
    \nonumber  \Pr[Z\le\frac{1}{2}(2n+1)]\le \delta
\end{align}
By Chernoff bound, we have:
\begin{align}
    \nonumber \Pr[Z \le (1-\epsilon) \mathbb{E}[Z]]\le \exp({-\frac{1}{2}\epsilon^2(2n+1)p})
\end{align}
Let $(1-\epsilon) \mathbb{E}[Z]= \frac{1}{2}(2n+1)$. Since $\mathbb{E}[Z]=(2n+1)p$, we can compute $\epsilon=1-\frac{1}{2p}$.
Since $p\in (\frac{1}{2},1)$, the $\epsilon \in (0,1) $.
Thus, we have $\Pr[Z \le \frac{1}{2}(2n+1)]\le \exp({\frac{-(2p-1)^2(2n+1)}{8p}})$.
Since we have to satisfy $\Pr[Z\le\frac{1}{2}(2n+1)]\le \delta$, then:
\begin{align}
    \nonumber \exp({\frac{-(2p-1)^2(2n+1)}{8p}}) \le \delta \implies 2n+1 \ge \frac{-8p\cdot \ln \delta }{(2p-1)^2}
\end{align}
\\
\noindent 1. \blue{\textbf{Integration by Sampling.}
Suppose we are given an integrable function 
$f : [0, 1]\rightarrow [0, M ]$,
and we wish to estimate the integral $I (f ) := \int_{0}^{1} f (x) \,dx$.
We only have \textbf{black box access} to the function $f$: 
this means that we are given a box such that 
when we provide it with a real number $x$, 
the box returns the value $f(x)$.
Moreover, we assume the real computation model. 
In particular, we assume that storing a real number takes constant space, 
and basic arithmetic and comparison operator ($\le$) take constant time.
Suppose we are also given a random number generator \textbf{Rand[0,1] }
that returns a number uniformly at random from $[0,1]$, 
and subsequent runs of \textbf{Rand[0,1]} are independent.
The goal is to design an algorithm that given black box access to a function 
$f : [0, 1]\rightarrow [0, M ]$ and parameters $0 < \epsilon ,\delta < 1$, 
return an estimate of $I(f)$ with additive error at most $\epsilon$ 
and failure probability at most $\delta$.
\\
(a) Show that this is not achievable by a deterministic algorithm. 
In particular, show that for any deterministic algorithm $A$, 
there is some function $f$ such that the algorithm $A$
returns an answer with additive error $\frac{M}{2}$ .
}\\
%We first consider the situation that algorithm $A$ does not rely on the black box.
%Since algorithm $A$ does not rely on the black box, 
%no matter what the function $f(x)$ is, it always return a constant $c$.
%If $c\le\frac{M}{2}$, set $f(x)=M$. If $c>\frac{M}{2}$, set $f(x)=0$.
%Thus the additive error is at least $\frac{M}{2}$.
Let $f_1:[0, 1]\rightarrow [0, M ]$ be any integrable function.
Use $f_1$ as an input of any deterministic algorithm $A$.
Since algorithm $A$ is a deterministic algorithm, $A$ is not allowed to access to the black box for infinite times.
%Let $f_1(x)$ be the input of algorithm $A$.
%Assume $n$ is the number of times that algorithm $A$ accesses to black box of $f_1$.
Let $x_1, x_2,...,x_n \in [0,1]$ be the $n$ real numbers that are submitted by algorithm $A$ to the black box of $f_1$.
By definition of \textbf{black box access}, for each $x_i$, $i\in\{1,2,...,n\}$, the black box of $f_1$ returns the value of $f_1(x_i)$.
%Let $n$ be the number of times that algorithm $A$ accesses to black box of $f_1$.
%Then we consider the case when algorithm $A$ accesses to black box for finite times, say $n$.
%Let the black box of $f_1(x)$ be the input of algorithm $A$, and 
Then, algorithm $A$ can get $n$ points: $(x_1,f_1(x_1)),(x_2,f_1(x_2)),...,(x_n,f_1(x_n))$.
%Let $(x_1,y_1),(x_2,y_2),...,(x_n,y_n)$ be the $n$ points. Here, for all $i\in\{1,2,...,n\}$, $y_i=f_1(x_i)$.
Finally, algorithm $A$ returns $c_1$ as the estimate of the integral of $f_1$.\\
%Let $c_1$ be the output of algorithm $A$ under the black box of function $f_1(x)$ as input.
%No matter how algorithm $A$ obtains the $x$ coordinates of the $n$ points, 
%we can always find a function $f_2(x)$ so that algorithm $A$ obtains the same coordinates of the $n$ points.
%Futhermore, for each $x_i$, $i\in \{1,2,...,n\}$, the output of  
%black boxes of both $f_1(x)$ and $f_2(x)$ are the same.  
Construct function $f_2:[0, 1]\rightarrow [0, M ]$ as follows. \\
If $c_1 \le \frac{M}{2}$:
\begin{equation}
   \nonumber  f_2(x)=
    \begin{cases}
    M& x\notin\{x_1,x_2,...,x_n\}\\
    f_1(x)& \text{otherwise}
    \end{cases}
\end{equation}
If $c_1 > \frac{M}{2}$:
\begin{equation}
   \nonumber  f_2(x)=
    \begin{cases}
    0& x\notin\{x_1,x_2,...,x_n\}\\
    f_1(x)& \text{otherwise}
    \end{cases}
\end{equation}
Since algorithm $A$ is a deterministic algorithm, 
at first, 
%, since algorithm $A$ only uses the black box of $f$ as input, 
for any black box of function $f$, if algorithm $A$ accesses the black box,
it always submits the same $x_1$ to the black box of function $f$.
Then algorithm $A$ uses $f(x_1)$ to decide whether to access the black box of function $f$ for one more time.
If the answer is access to the black box of function $f$, algorithm $A$ decides which real number to be submitted according to $f(x_1)$.
In conclude, algorithm $A$ uses $f(x_1), f(x_2),...,f(x_i)$ to decide whether $x_{i+1}$ exists and the value of $x_{i+1}$.
So, for $f_1$ and $f_2$, algorithm $A$ uses the same $n$ points $(x_1,f_1(x_1)),(x_2,f_1(x_2)),...,(x_n,f_1(x_n))$.
Since algorithm $A$ is a deterministic algorithm, 
algorithm $A$ returns $c_1$ as the estimate of the integral of $f_2$, which is the same output when input is the black box of $f_1$.
%the output of algorithm $A$ under the black box of function $f_2$ as input is also $c_1$.
When $c_1 \le \frac{M}{2}$, we have $\int_{0}^{1} f_2(x) \,dx=M$.
When $c_1 > \frac{M}{2}$, we have $\int_{0}^{1} f_2(x) \,dx=0$.
Thus, we can always find an integrable function 
$f_2 : [0, 1]\rightarrow [0, M]$ so that the additive error $|\int_{0}^{1} f_2(x) \,dx - c_1|$ is at least $\frac{M}{2}$.
\\
\noindent \blue{(b) Using the random generator \textbf{Rand[0,1]}, 
design a randomized algorithm to achieve the desired goal.
Give the number of black box accesses to the function $f$ 
and the number of accesses to \textbf{Rand[0,1]} used by your algorithm.}\\
The randomized algorithm is as follows.
\begin{enumerate}
    \item Use \textbf{Rand[0, 1]} for $n$ times and get $n$ random numbers.
    Here, $n=\lceil \frac{M^2(\ln \frac{2}{\delta})}{2\epsilon^2}\rceil $.
    Denote the $n$ random numbers as $X_1, X_2, ..., X_{n}$.
    \item For each $X_i$, $i\in \{1,2,...,n\}$, use \textbf{black box access} to get $f(X_i)$.
    Let $Y=\sum_{i\in n}f(X_i)$.
    \item Return $\frac{Y}{n}$ as the estimate of $I(f)$.
\end{enumerate}
\textbf{Analysis:}\\
Since \textbf{Rand[0,1]} can generate random number independent,
$X_1, X_2,..., X_{n}$ are independent.
And then, $f(X_1), f(X_2),..., f(X_{n})$ are independent.
Furthermore, all of the $f(X_i)$s take values from the interval $[0, M]$.
$Y=\sum_{i\in n}f(X_i)$, by definition, we have $\mathbb{E}[\frac{Y}{n}]=I(f)$.
By Hoeffding's Inequality, we have:
\begin{align}
    \nonumber \Pr[|\frac{Y}{n}-I(f)|\ge\epsilon]=\Pr[|\frac{Y}{n}-\mathbb{E}[\frac{Y}{n}]|\ge\epsilon]
    =\Pr[|Y-\mathbb{E}[Y]|\ge n\epsilon]\le 2\exp({\frac{-2n\epsilon^2}{M^2}})
\end{align}
What we need to satisfy is $\Pr[|\frac{Y}{n}-I(f)|\ge\epsilon]\le \delta$, then,
\begin{align}
    \nonumber 2\exp({\frac{-2n\epsilon^2}{M^2}}) \le \delta \implies n\ge \frac{M^2\ln \frac{2}{\delta}}{2\epsilon^2}
\end{align}
3.\blue{\textbf{Estimating the (Unknown) Fraction of Red Balls.}
Suppose a bag contains an unknown number of red balls (assume there is at least one red ball) 
and you are only allowed to sample (with replacement) uniformly at random from the bag. 
Design an algorithm that, given $0<\epsilon,\delta <1$, with failure probability at most $\delta$, 
returns an estimate of the fraction of red balls with multiplicative error at most $\epsilon$,
i.e., if the real fraction is $p$, the algorithm returns a number $\widehat{p}$ such that $|p-\widehat{p}|\le \epsilon p$.
Give the number of random samples used by your algorithm.
}
